from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage
from tools import get_balance, process_transaction, log_complaint, log_transaction, get_transaction_history
import datetime

def financial_agent(state):
    """Handles balance inquiries and returns the correct balance."""
    customer_id = state.get("customer_id", None)

    if not customer_id:
        return {
            "messages": state["messages"] + [AIMessage(content="âŒ LÃ¼tfen mÃ¼ÅŸteri numaranÄ±zÄ± belirtin.")],
            "next": "END"
        }

    # âœ… Retrieve balance from `get_balance`
    balance_response = get_balance.invoke({"customer_id": customer_id})

    # âœ… Ensure AIMessage response is correctly returned
    return {
        "messages": state["messages"] + [AIMessage(content=f"ğŸ’³ {balance_response}")],
        "next": "END"
    }


def transaction_agent(state):
    """Handles transaction requests using AI to extract details dynamically and logs transactions."""
    last_message = state["messages"][-1].content
    sender_customer_id = state.get("customer_id", None)

    if not sender_customer_id:
        return {
            "messages": state["messages"] + [AIMessage(content="âŒ LÃ¼tfen mÃ¼ÅŸteri numaranÄ±zÄ± belirtin.")],
            "next": "END"
        }

    llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18")
    response = llm.invoke(
        f"KullanÄ±cÄ±nÄ±n mesajÄ±ndaki iÅŸlem detaylarÄ±nÄ± Ã§Ä±kar: {last_message}. "
        "YanÄ±t ÅŸu formatta olmalÄ±dÄ±r: 'AMOUNT: <tutar>, RECEIVER_ID: <alÄ±cÄ±_id>'. "
        "EÄŸer mesajda gerekli bilgiler eksikse 'ERROR: Bilgiler eksik' ÅŸeklinde yanÄ±t ver."
    )
    response_text = response.content.strip()

    if "ERROR" in response_text:
        return {
            "messages": state["messages"] + [
                AIMessage(content="âš ï¸ Hata: LÃ¼tfen gÃ¶nderilecek miktarÄ± ve alÄ±cÄ± hesap numarasÄ±nÄ± belirtin.")],
            "next": "END"
        }

    try:
        extracted_data = {pair.split(": ")[0]: pair.split(": ")[1] for pair in response_text.split(", ")}
        amount = float(extracted_data["AMOUNT"])
        receiver_customer_id = int(extracted_data["RECEIVER_ID"])
    except (KeyError, ValueError):
        return {
            "messages": state["messages"] + [AIMessage(content="âš ï¸ Hata: Ä°ÅŸlem detaylarÄ± doÄŸru formatta deÄŸil.")],
            "next": "END"
        }

    transaction_response = process_transaction.invoke({
        "sender_customer_id": sender_customer_id,
        "receiver_customer_id": receiver_customer_id,
        "amount": amount
    })

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_transaction.invoke(
        {"customer_id": sender_customer_id, "transaction_details": f"[{timestamp}] {transaction_response}"})

    return {
        "messages": state["messages"] + [AIMessage(content=transaction_response)],
        "next": "END"
    }


def transaction_history_agent(state):
    """Retrieves the customer's transaction history."""
    customer_id = state.get("customer_id", None)

    if not customer_id:
        return {
            "messages": state["messages"] + [AIMessage(content="âŒ LÃ¼tfen mÃ¼ÅŸteri numaranÄ±zÄ± belirtin.")],
            "next": "END"
        }

    # âœ… Fetch transaction history properly
    history_response = get_transaction_history.invoke({"customer_id": customer_id})

    return {
        "messages": state["messages"] + [AIMessage(content=history_response)],
        "next": "END"
    }


def complaint_agent(state):
    """Handles customer complaints using AI-driven extraction."""
    last_message = state["messages"][-1].content
    customer_id = state.get("customer_id", None)

    if not customer_id:
        return {
            "messages": state["messages"] + [AIMessage(content="âŒ LÃ¼tfen mÃ¼ÅŸteri numaranÄ±zÄ± belirtin.")],
            "next": "END"
        }

    # âœ… Use AI to extract complaint details dynamically
    llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18")
    response = llm.invoke(
        f"KullanÄ±cÄ±nÄ±n mesajÄ±ndaki ÅŸikayeti anlamlandÄ±r: {last_message}. "
        "YanÄ±t ÅŸu formatta olmalÄ±dÄ±r: 'COMPLAINT: <ÅŸikayet_detayÄ±>'. "
        "EÄŸer mesajda bir ÅŸikayet tespit edilemiyorsa 'ERROR: Åikayet tespit edilmedi' ÅŸeklinde yanÄ±t ver."
    )
    response_text = response.content.strip()

    if "ERROR" in response_text:
        return {
            "messages": state["messages"] + [
                AIMessage(content="âš ï¸ Hata: Åikayet algÄ±lanamadÄ±. LÃ¼tfen detaylÄ± aÃ§Ä±klayÄ±n.")],
            "next": "END"
        }

    # âœ… Extract complaint details
    try:
        complaint_text = response_text.split(": ")[1]
    except IndexError:
        return {
            "messages": state["messages"] + [AIMessage(content="âš ï¸ Hata: Åikayet detaylarÄ± doÄŸru formatta deÄŸil.")],
            "next": "END"
        }

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_complaint.invoke({"customer_id": customer_id, "complaint_text": f"[{timestamp}] {complaint_text}"})

    return {
        "messages": state["messages"] + [AIMessage(
            content="ğŸ“© Åikayetiniz baÅŸarÄ±yla kaydedildi. Yetkililerimiz en kÄ±sa sÃ¼rede sizinle iletiÅŸime geÃ§ecektir.")],
        "next": "END"
    }


def query_agent(state):
    """Handles general queries using an AI model. If unrelated, suggests relevant topics."""
    last_message = state["messages"][-1].content
    llm = ChatOpenAI(model="gpt-4o-mini-2024-07-18")
    response = llm.invoke(f"KullanÄ±cÄ±nÄ±n sorduÄŸu genel soruyu yanÄ±tla: {last_message}")

    ai_response = response.content.strip()

    if "ERROR" in ai_response or "anlamÄ±yorum" in ai_response.lower():
        ai_response = ("ğŸ“Œ Bu sistem aÅŸaÄŸÄ±daki konular hakkÄ±nda yardÄ±mcÄ± olabilir:\n"
                       "- Bakiye sorgulama\n"
                       "- Para transferi iÅŸlemleri\n"
                       "- Ä°ÅŸlem geÃ§miÅŸi\n"
                       "- Åikayet bildirimi\n"
                       "LÃ¼tfen bu konulardan birini seÃ§iniz.")

    return {
        "messages": state["messages"] + [AIMessage(content=ai_response)],
        "next": "END"
    }