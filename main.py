from langchain_openai import ChatOpenAI
from config import df
from workflow import build_workflow
from langchain.schema import HumanMessage, AIMessage


# Function to generate customer name dynamically
def get_customer_name_from_data(customer_id):
    customer_row = df[df["CustomerId"] == customer_id]
    if not customer_row.empty:
        surname = customer_row.iloc[0]["Surname"]
        gender = customer_row.iloc[0]["Gender"]
        title = "Bey" if gender == "Male" else "HanÄ±m"
        return f"{surname} {title}"
    return "DeÄŸerli MÃ¼ÅŸterimiz"


# Initialize LLM for conversation analysis
llm = ChatOpenAI(model_name="gpt-4", temperature=0.3)


def detect_conversation_end(messages):
    """Uses LLM to determine if the conversation should end."""
    analysis_prompt = "AÅŸaÄŸÄ±daki konuÅŸmayÄ± analiz et ve kullanÄ±cÄ±nÄ±n baÅŸka bir ihtiyacÄ± olup olmadÄ±ÄŸÄ±nÄ± tespit et.\n\n"
    analysis_prompt += "\n\n".join([f"KullanÄ±cÄ±: {msg.content}" for msg in messages if isinstance(msg, HumanMessage)])
    analysis_prompt += "\n\nChatbot'un konuÅŸmayÄ± sonlandÄ±rmasÄ± gerekiyor mu? EÄŸer evet, 'EVET' yaz, eÄŸer hayÄ±r, 'HAYIR' yaz."

    response = llm.predict(analysis_prompt)
    return "EVET" in response.upper()


def main():
    print("\nğŸ’¬ Chatbot hazÄ±r! Ã‡Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' veya 'exit' yazÄ±n.\n")

    customer_id = input("ğŸ”‘ LÃ¼tfen mÃ¼ÅŸteri numaranÄ±zÄ± girin: ")

    if not customer_id.isdigit():
        print("âŒ GeÃ§ersiz mÃ¼ÅŸteri numarasÄ±. LÃ¼tfen sayÄ±sal bir deÄŸer girin.")
        return

    customer_id = int(customer_id)
    customer_name = get_customer_name_from_data(customer_id)  # Generate customer name dynamically

    print(f"\nğŸ¤– Bot: Merhaba {customer_name}, size nasÄ±l yardÄ±mcÄ± olabilirim?")

    workflow = build_workflow()
    compiled_workflow = workflow.compile()
    state = {"messages": [], "customer_id": customer_id, "customer_name": customer_name}

    while True:
        user_input = input("\nğŸ‘¤ Siz: ")
        if user_input.lower() in ["Ã§Ä±kÄ±ÅŸ", "exit"]:
            print(f"\nğŸ¤– Bot: {customer_name}, iyi gÃ¼nler dilerim! ğŸ‘‹")
            break

        state["messages"].append(HumanMessage(content=user_input))
        state = compiled_workflow.invoke(state)
        messages = state["messages"]

        bot_response = next((msg.content for msg in reversed(messages) if isinstance(msg, AIMessage)),
                            "ÃœzgÃ¼nÃ¼m, isteÄŸinizi anlayamadÄ±m.")

        print(f"\nğŸ¤– Bot: {bot_response.replace('MÃ¼ÅŸteri', customer_name)}")

        # Check if conversation should end using LLM
        if detect_conversation_end(state["messages"]):
            print(f"\nğŸ¤– Bot: {customer_name}, size yardÄ±mcÄ± olabildiysem ne mutlu! Ä°yi gÃ¼nler dilerim! ğŸ‘‹")
            break


if __name__ == "__main__":
    main()
